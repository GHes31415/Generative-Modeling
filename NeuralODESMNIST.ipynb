{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM+nTUReuHDcX7XUp8bu9y9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GHes31415/Generative-Modeling/blob/main/NeuralODESMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-6Ox2VRGGD_",
        "outputId": "39f6b2da-42bc-4664-ac5b-b6a58924e811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdiffeq\n",
            "  Downloading torchdiffeq-0.2.3-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (2.0.1+cu118)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy>=1.4.0->torchdiffeq) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->torchdiffeq) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.0->torchdiffeq) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->torchdiffeq) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->torchdiffeq) (1.3.0)\n",
            "Installing collected packages: torchdiffeq\n",
            "Successfully installed torchdiffeq-0.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install torchdiffeq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchdiffeq import odeint_adjoint as odeint\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U_xeJXgzLl5o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(0.5,0.5)])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4tSS3y6MLzz2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.MNIST(root = '../data',train = True,\n",
        "                                      download = True, transform = transform)\n"
      ],
      "metadata": {
        "id": "svd5BOQMMxZb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b114ad-d599-49f7-9fe3-631b2c525824"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 237292098.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 42459058.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 48215196.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 22307410.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size = 16,\n",
        "                                          shuffle = True, num_workers=4)\n",
        "testset = torchvision.datasets.MNIST(root = '../data', train = False,\n",
        "                                     download = True, transform = transform)\n",
        "testloader = torch.utils.data.DataLoader(testset,batch_size = 16,\n",
        "                                         shuffle = True, num_workers = 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3H1WT8BM2Pc",
        "outputId": "e2a8c15b-4741-47d1-d87f-32b8adf2f87d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNet(nn.Module):\n",
        "\tdef __init__(self, path):\n",
        "\t\tsuper(MyNet, self).__init__()\n",
        "\t\tself.path = path\n",
        "\n",
        "\tdef num_params(self):\n",
        "\t\treturn sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "\tdef load(self):\n",
        "\t\tself.load_state_dict(torch.load('./' + self.path + '.pth'))"
      ],
      "metadata": {
        "id": "pr321ftENPTP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We consider an autonomous ODE with $$f(x,a) = gn\\circ conv(a)\\circ relu\\circ gn$$\n",
        "\n",
        "with gn the GroupNorm function, a are the set of parameters of the convolution."
      ],
      "metadata": {
        "id": "soWZR1V5B-or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ODEFunc(nn.Module):\n",
        "\tdef __init__(self, dim):\n",
        "\t\tsuper(ODEFunc, self).__init__()\n",
        "\t\tself.gn = nn.GroupNorm(min(32, dim), dim)\n",
        "\t\tself.conv = nn.Conv2d(dim, dim, 3, padding = 1)\n",
        "\t\tself.nfe = 0 # time counter\n",
        "\n",
        "\tdef forward(self, t, x):\n",
        "\t\tself.nfe += 1\n",
        "\t\tx = self.gn(x)\n",
        "\t\tx = F.relu(x)\n",
        "\t\tx = self.conv(x)\n",
        "\t\tx = self.gn(x)\n",
        "\t\treturn x"
      ],
      "metadata": {
        "id": "bC8IXlsQB7bU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integrator of neural ODE"
      ],
      "metadata": {
        "id": "nzxlYXquDGTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ODEBlock(nn.Module):\n",
        "\tdef __init__(self, odefunc):\n",
        "\t\tsuper(ODEBlock, self).__init__()\n",
        "\t\tself.odefunc = odefunc\n",
        "\t\tself.integration_time = torch.tensor([0, 1]).float()\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tout = odeint(self.odefunc, x, self.integration_time, rtol=1e-1, atol=1e-1) # high tolerances for speed\n",
        "\n",
        "\t\t# first dimension is x(0) and second is x(1),\n",
        "\t\t# so we just want the second\n",
        "\t\treturn out[1]\n"
      ],
      "metadata": {
        "id": "hpHOSbQHDBTC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we create ODENet with this block. There are thre parts to this ODENet.\n",
        "\n",
        "\n",
        "1.   We take our 28-by-28 image and apply a  3-by-3 convolution without padding to it with 6 output channels. Then we apply GropuNorm and ReLu\n",
        "2.   WE apply the ODEBlock\n",
        "3.   WE apply a 2-by-2 average pool and one fully connected linear layer. \n",
        "\n"
      ],
      "metadata": {
        "id": "DGtredDJEIAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ODENet(MyNet):\n",
        "  def __init__(self):\n",
        "    super(ODENet, self).__init__('mnist_odenet')\n",
        "    self.conv1 = nn.Conv2d(1, 2, 3) #( in channels, out channels ,filter size)\n",
        "    self.gn = nn.GroupNorm(2, 2)\n",
        "    self.odefunc = ODEFunc(2)\n",
        "    self.odeblock = ODEBlock(self.odefunc)\n",
        "    self.pool = nn.AvgPool2d(2)\n",
        "    self.fc = nn.Linear(2* 13 * 13, 10)\n",
        "  def forward(self,x):\n",
        "    #26x26\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(self.gn(x))\n",
        "\n",
        "    # stays 26x26\n",
        "    x = self.odeblock(x)\n",
        "\n",
        "    # 13x13\n",
        "    x = self.pool(x)\n",
        "\n",
        "    #fully connected layer\n",
        "    x = x.view(-1,2*13*13)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  # def forward(self, x):\n",
        "  #   # 26 x 26\n",
        "  #   x = self.conv1(x)\n",
        "  #   x = F.relu(self.gn(x))\n",
        "\n",
        "  #   # stays 26 x 26\n",
        "  #   x = self.odeblock(x)\n",
        "\n",
        "  #   # 13 x 13\n",
        "  #   x = self.pool(x)\n",
        "\n",
        "  #   # fully connected layer\n",
        "  #   x = x.view(-1, 6*13*13)\n",
        "  #   x = self.fc(x)\n",
        "\n",
        "  #   return x"
      ],
      "metadata": {
        "id": "F2veCsPsEFYY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now training and testing method"
      ],
      "metadata": {
        "id": "d8mu-x8bHUsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net):\n",
        "  n = 60000/(5*16) # batch size 16\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(net.parameters(),lr = 0.001, momentum = 0.9)\n",
        "\n",
        "  for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i,data in enumerate(trainloader,0):\n",
        "      # get the inputs; data is a list of [inputs, labels]\n",
        "      inputs, labels = data\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      #foward + backward+ optimize\n",
        "\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      #print statistics\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      if i%n == n-1:\n",
        "        print('[%d,%5d] loss: %.3f'% (epoch +1, i+1, running_loss/n))\n",
        "        running_loss = 0.0\n",
        "        torch.save(net.state_dict(),'./'+ net.path +'.pth')\n",
        "  print('Finished Training')\n",
        "  torch.save(net.state_dict(),'./'+ net.path +'.pth')\n",
        "\n",
        "def test(net):\n",
        "  initial_time = time.time()\n",
        "  correct = 0 \n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for data in testloader:\n",
        "      images,labels = data\n",
        "      batch_size = images.shape[0]\n",
        "      outputs = net(images)\n",
        "      _, predicted = torch.max(outputs.data,1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted==labels).sum().item()\n",
        "  final_time = time.time()\n",
        "  print('Accuracy of the ' + net.path + ' network on the test set: %.2f %%' % (100 * correct / total))\n",
        "  print('Time: %.2f seconds' % (final_time - initial_time))\n",
        "  return(100 * correct / total)\n"
      ],
      "metadata": {
        "id": "yTnzN1mGFc7s"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "odenet = ODENet()\n",
        "train(odenet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7-DhY6yMYLK",
        "outputId": "8acbf6b9-4089-43b3-e1e7-0100dde805db"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  750] loss: 0.549\n",
            "[1, 1500] loss: 0.370\n",
            "[1, 2250] loss: 0.346\n",
            "[1, 3000] loss: 0.363\n",
            "[1, 3750] loss: 0.300\n",
            "[2,  750] loss: 0.200\n",
            "[2, 1500] loss: 0.168\n",
            "[2, 2250] loss: 0.140\n",
            "[2, 3000] loss: 0.141\n",
            "[2, 3750] loss: 0.135\n",
            "[3,  750] loss: 0.121\n",
            "[3, 1500] loss: 0.115\n",
            "[3, 2250] loss: 0.123\n",
            "[3, 3000] loss: 0.117\n",
            "[3, 3750] loss: 0.121\n",
            "[4,  750] loss: 0.115\n",
            "[4, 1500] loss: 0.111\n",
            "[4, 2250] loss: 0.109\n",
            "[4, 3000] loss: 0.109\n",
            "[4, 3750] loss: 0.117\n",
            "[5,  750] loss: 0.103\n",
            "[5, 1500] loss: 0.107\n",
            "[5, 2250] loss: 0.108\n",
            "[5, 3000] loss: 0.105\n",
            "[5, 3750] loss: 0.114\n",
            "[6,  750] loss: 0.094\n",
            "[6, 1500] loss: 0.106\n",
            "[6, 2250] loss: 0.108\n",
            "[6, 3000] loss: 0.111\n",
            "[6, 3750] loss: 0.103\n",
            "[7,  750] loss: 0.102\n",
            "[7, 1500] loss: 0.101\n",
            "[7, 2250] loss: 0.096\n",
            "[7, 3000] loss: 0.098\n",
            "[7, 3750] loss: 0.101\n",
            "[8,  750] loss: 0.097\n",
            "[8, 1500] loss: 0.110\n",
            "[8, 2250] loss: 0.088\n",
            "[8, 3000] loss: 0.102\n",
            "[8, 3750] loss: 0.098\n",
            "[9,  750] loss: 0.093\n",
            "[9, 1500] loss: 0.103\n",
            "[9, 2250] loss: 0.092\n",
            "[9, 3000] loss: 0.102\n",
            "[9, 3750] loss: 0.096\n",
            "[10,  750] loss: 0.095\n",
            "[10, 1500] loss: 0.098\n",
            "[10, 2250] loss: 0.095\n",
            "[10, 3000] loss: 0.095\n",
            "[10, 3750] loss: 0.094\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(odenet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvL7asunM3LM",
        "outputId": "43acbfbc-967e-4a58-bd46-59700f7d2870"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the mnist_odenet network on the test set: 96.91 %\n",
            "Time: 16.66 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96.91"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pTBya2NbNx67"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}